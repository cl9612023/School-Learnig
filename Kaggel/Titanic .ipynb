{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggel1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7Pp2X8RXoj7",
        "outputId": "9115e767-c180-454e-aab1-5031009c86dd"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B4iyDgKlX05N",
        "outputId": "d76d6450-d640-4b4d-fec9-964bc31eebba"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/kaggel/train.csv')#讀檔\n",
        "row_name=list(data.columns)#讀資料種類\n",
        "#刪掉無用資料\n",
        "delet_col = [row_name[0],row_name[3],row_name[8],row_name[9]]\n",
        "data_new = data.drop(delet_col, axis=1)\n",
        "#將男女以1和0表示\n",
        "data_new = data_new.replace(['male', 'female'],[1, 0])\n",
        "data_new[row_name[11]]=data_new[row_name[11]].fillna(0)\n",
        "data_new[row_name[11]]= data_new[row_name[11]].replace(['C','S','Q'],[1 ,2 ,3])\n",
        "#將歲數為na的以平均值表示\n",
        "data_new['Age'] = data_new['Age'].fillna(value=data_new['Age'].mean())\n",
        "#將cabin中的數值以0或1表示\n",
        "strlist = list(data_new['Cabin'].unique())\n",
        "data_new['Cabin']=data_new['Cabin'].fillna(0)\n",
        "for element in strlist:\n",
        "    data_new['Cabin']=data_new['Cabin'].replace(element,1)\n",
        "    \n",
        "\n",
        "num = data_new[row_name[1]].value_counts()#統計生和死個數\n",
        "#分為生和死的資料\n",
        "data_live = data_new[data_new[row_name[1]]==1]\n",
        "data_die = data_new[data_new[row_name[1]]==0]\n",
        "#分析哪些會影響結果的因素\n",
        "row_name2=list(data_live.columns)\n",
        "for i in range(1,8):\n",
        "    print(row_name2[i])\n",
        "    plt.bar(data_live[row_name2[i]].unique(), data_live[row_name2[i]].value_counts())\n",
        "    plt.show()\n",
        "    plt.bar(data_die[row_name2[i]].unique(), data_die[row_name2[i]].value_counts())\n",
        "    plt.show()\n",
        "    print()\n",
        "\n",
        "\n",
        "anwser = data_new[row_name[1]]\n",
        "delet_col = [row_name[1]]\n",
        "data_new = data_new.drop(delet_col, axis=1)\n",
        "print(data_new.shape)\n",
        "print(anwser.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_new, anwser,test_size=0.1)\n",
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
        "\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D, Activation,BatchNormalization\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "def create_dlp(dim, regress=False):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128, input_dim=dim, activation=\"relu\"))\n",
        "  model.add(Dense(256, activation=\"relu\"))\n",
        "  model.add(Dense(256, activation=\"relu\"))\n",
        "  model.add(Dense(256, activation=\"relu\"))\n",
        "  if regress:\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "  return model\n",
        "model = create_dlp(4,regress=True)\n",
        "model.compile(loss='mean_squared_error', optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pclass\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sex\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Age\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "SibSp\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Cabin\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Embarked\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "(891, 7)\n",
            "(891,)\n",
            "(801, 7) (90, 7) (801,) (90,)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 128)               640       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 165,505\n",
            "Trainable params: 165,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfn6KsM5Y5tC",
        "outputId": "26847d21-98ab-4fce-c58a-3e4875172bdd"
      },
      "source": [
        "#earlystop = EarlyStopping(monitor='accuracy', patience=100,verbose=2)\n",
        "rle = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=20,verbose=1,min_lr=1e-10)\n",
        "history = model.fit(X_train, y_train,validation_data=(X_test, y_test),\n",
        "          epochs=10000, batch_size=32,verbose=2,callbacks = [rle])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m串流輸出內容已截斷至最後 5000 行。\u001b[0m\n",
            "Epoch 7620/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7621/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7622/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7623/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7624/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7625/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7626/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7627/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7628/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7629/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7630/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7631/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7632/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7633/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7634/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7635/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7636/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7637/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7638/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7639/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07639: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7640/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7641/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7642/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7643/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7644/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7645/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7646/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7647/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7648/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7649/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7650/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7651/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7652/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7653/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7654/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7655/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7656/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7657/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7658/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7659/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07659: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7660/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7661/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7662/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7663/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7664/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7665/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7666/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7667/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7668/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7669/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7670/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7671/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7672/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7673/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7674/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7675/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7676/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7677/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7678/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7679/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07679: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7680/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7681/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7682/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7683/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7684/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7685/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7686/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7687/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7688/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7689/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7690/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7691/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7692/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7693/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7694/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7695/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7696/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7697/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7698/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7699/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07699: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7700/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7701/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7702/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7703/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7704/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7705/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7706/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7707/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7708/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7709/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7710/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7711/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7712/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7713/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7714/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7715/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7716/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7717/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7718/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7719/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07719: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7720/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7721/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7722/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7723/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7724/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7725/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7726/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7727/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7728/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7729/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7730/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7731/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7732/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7733/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7734/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7735/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7736/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7737/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7738/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7739/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07739: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7740/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7741/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7742/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7743/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7744/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7745/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7746/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7747/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7748/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7749/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7750/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7751/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7752/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7753/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7754/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7755/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7756/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7757/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7758/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7759/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07759: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7760/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7761/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7762/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7763/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7764/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7765/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7766/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7767/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7768/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7769/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7770/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7771/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7772/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7773/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7774/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7775/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7776/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7777/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7778/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7779/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07779: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7780/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7781/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7782/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7783/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7784/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7785/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7786/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7787/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7788/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7789/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7790/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7791/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7792/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7793/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7794/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7795/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7796/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7797/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7798/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7799/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07799: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7800/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7801/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7802/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7803/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7804/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7805/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7806/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7807/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7808/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7809/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7810/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7811/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7812/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7813/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7814/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7815/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7816/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7817/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7818/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7819/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07819: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7820/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7821/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7822/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7823/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7824/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7825/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7826/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7827/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7828/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7829/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7830/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7831/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7832/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7833/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7834/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7835/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7836/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7837/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7838/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7839/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07839: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7840/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7841/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7842/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7843/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7844/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7845/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7846/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7847/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7848/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7849/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7850/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7851/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7852/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7853/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7854/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7855/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7856/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7857/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7858/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7859/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07859: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7860/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7861/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7862/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7863/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7864/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7865/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7866/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7867/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7868/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7869/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7870/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7871/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7872/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7873/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7874/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7875/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7876/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7877/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7878/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7879/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07879: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7880/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7881/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7882/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7883/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7884/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7885/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7886/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7887/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7888/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7889/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7890/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7891/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7892/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7893/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7894/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7895/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7896/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7897/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7898/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7899/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07899: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7900/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7901/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7902/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7903/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7904/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7905/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7906/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7907/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7908/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7909/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7910/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7911/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7912/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7913/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7914/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7915/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7916/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7917/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7918/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7919/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07919: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7920/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7921/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7922/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7923/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7924/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7925/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7926/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7927/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7928/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7929/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7930/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7931/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7932/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7933/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7934/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7935/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7936/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7937/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7938/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7939/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07939: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7940/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7941/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7942/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7943/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7944/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7945/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7946/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7947/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7948/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7949/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7950/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7951/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7952/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7953/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7954/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7955/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7956/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7957/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7958/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7959/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07959: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7960/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7961/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7962/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7963/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7964/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7965/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7966/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7967/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7968/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7969/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7970/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7971/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7972/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7973/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7974/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7975/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7976/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7977/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7978/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7979/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07979: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 7980/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7981/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7982/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7983/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7984/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7985/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7986/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7987/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7988/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7989/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7990/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7991/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7992/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7993/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7994/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7995/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7996/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7997/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7998/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 7999/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 07999: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8000/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8001/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8002/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8003/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8004/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8005/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8006/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8007/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8008/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8009/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8010/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8011/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8012/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8013/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8014/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8015/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8016/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8017/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8018/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8019/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08019: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8020/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8021/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8022/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8023/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8024/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8025/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8026/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8027/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8028/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8029/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8030/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8031/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8032/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8033/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8034/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8035/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8036/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8037/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8038/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8039/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08039: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8040/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8041/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8042/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8043/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8044/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8045/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8046/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8047/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8048/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8049/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8050/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8051/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8052/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8053/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8054/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8055/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8056/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8057/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8058/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8059/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08059: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8060/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8061/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8062/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8063/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8064/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8065/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8066/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8067/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8068/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8069/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8070/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8071/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8072/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8073/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8074/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8075/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8076/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8077/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8078/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8079/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08079: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8080/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8081/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8082/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8083/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8084/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8085/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8086/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8087/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8088/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8089/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8090/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8091/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8092/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8093/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8094/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8095/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8096/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8097/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8098/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8099/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08099: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8100/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8101/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8102/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8103/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8104/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8105/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8106/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8107/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8108/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8109/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8110/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8111/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8112/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8113/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8114/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8115/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8116/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8117/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8118/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8119/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08119: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8120/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8121/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8122/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8123/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8124/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8125/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8126/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8127/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8128/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8129/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8130/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8131/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8132/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8133/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8134/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8135/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8136/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8137/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8138/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8139/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08139: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8140/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8141/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8142/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8143/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8144/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8145/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8146/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8147/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8148/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8149/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8150/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8151/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8152/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8153/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8154/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8155/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8156/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8157/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8158/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8159/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08159: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8160/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8161/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8162/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8163/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8164/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8165/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8166/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8167/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8168/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8169/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8170/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8171/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8172/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8173/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8174/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8175/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8176/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8177/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8178/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8179/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08179: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8180/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8181/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8182/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8183/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8184/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8185/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8186/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8187/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8188/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8189/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8190/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8191/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8192/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8193/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8194/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8195/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8196/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8197/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8198/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8199/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08199: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8200/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8201/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8202/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8203/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8204/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8205/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8206/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8207/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8208/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8209/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8210/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8211/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8212/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8213/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8214/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8215/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8216/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8217/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8218/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8219/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08219: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8220/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8221/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8222/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8223/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8224/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8225/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8226/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8227/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8228/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8229/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8230/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8231/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8232/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8233/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8234/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8235/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8236/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8237/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8238/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8239/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08239: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8240/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8241/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8242/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8243/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8244/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8245/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8246/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8247/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8248/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8249/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8250/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8251/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8252/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8253/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8254/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8255/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8256/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8257/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8258/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8259/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08259: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8260/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8261/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8262/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8263/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8264/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8265/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8266/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8267/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8268/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8269/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8270/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8271/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8272/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8273/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8274/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8275/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8276/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8277/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8278/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8279/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08279: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8280/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8281/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8282/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8283/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8284/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8285/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8286/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8287/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8288/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8289/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8290/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8291/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8292/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8293/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8294/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8295/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8296/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8297/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8298/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8299/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08299: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8300/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8301/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8302/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8303/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8304/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8305/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8306/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8307/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8308/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8309/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8310/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8311/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8312/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8313/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8314/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8315/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8316/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8317/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8318/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8319/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08319: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8320/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8321/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8322/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8323/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8324/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8325/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8326/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8327/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8328/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8329/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8330/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8331/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8332/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8333/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8334/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8335/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8336/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8337/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8338/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8339/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08339: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8340/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8341/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8342/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8343/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8344/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8345/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8346/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8347/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8348/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8349/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8350/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8351/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8352/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8353/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8354/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8355/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8356/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8357/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8358/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8359/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08359: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8360/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8361/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8362/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8363/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8364/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8365/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8366/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8367/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8368/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8369/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8370/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8371/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8372/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8373/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8374/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8375/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8376/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8377/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8378/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8379/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08379: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8380/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8381/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8382/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8383/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8384/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8385/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8386/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8387/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8388/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8389/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8390/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8391/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8392/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8393/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8394/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8395/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8396/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8397/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8398/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8399/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08399: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8400/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8401/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8402/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8403/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8404/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8405/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8406/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8407/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8408/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8409/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8410/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8411/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8412/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8413/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8414/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8415/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8416/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8417/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8418/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8419/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08419: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8420/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8421/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8422/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8423/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8424/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8425/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8426/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8427/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8428/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8429/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8430/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8431/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8432/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8433/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8434/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8435/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8436/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8437/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8438/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8439/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08439: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8440/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8441/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8442/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8443/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8444/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8445/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8446/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8447/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8448/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8449/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8450/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8451/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8452/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8453/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8454/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8455/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8456/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8457/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8458/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8459/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08459: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8460/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8461/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8462/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8463/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8464/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8465/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8466/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8467/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8468/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8469/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8470/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8471/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8472/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8473/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8474/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8475/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8476/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8477/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8478/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8479/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08479: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8480/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8481/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8482/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8483/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8484/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8485/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8486/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8487/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8488/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8489/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8490/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8491/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8492/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8493/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8494/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8495/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8496/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8497/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8498/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8499/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08499: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8500/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8501/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8502/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8503/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8504/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8505/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8506/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8507/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8508/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8509/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8510/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8511/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8512/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8513/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8514/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8515/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8516/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8517/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8518/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8519/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08519: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8520/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8521/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8522/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8523/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8524/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8525/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8526/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8527/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8528/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8529/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8530/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8531/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8532/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8533/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8534/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8535/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8536/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8537/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8538/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8539/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08539: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8540/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8541/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8542/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8543/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8544/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8545/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8546/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8547/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8548/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8549/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8550/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8551/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8552/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8553/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8554/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8555/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8556/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8557/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8558/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8559/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08559: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8560/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8561/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8562/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8563/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8564/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8565/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8566/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8567/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8568/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8569/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8570/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8571/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8572/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8573/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8574/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8575/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8576/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8577/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8578/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8579/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08579: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8580/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8581/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8582/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8583/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8584/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8585/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8586/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8587/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8588/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8589/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8590/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8591/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8592/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8593/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8594/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8595/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8596/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8597/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8598/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8599/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08599: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8600/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8601/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8602/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8603/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8604/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8605/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8606/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8607/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8608/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8609/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8610/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8611/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8612/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8613/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8614/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8615/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8616/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8617/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8618/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8619/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08619: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8620/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8621/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8622/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8623/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8624/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8625/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8626/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8627/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8628/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8629/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8630/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8631/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8632/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8633/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8634/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8635/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8636/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8637/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8638/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8639/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08639: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8640/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8641/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8642/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8643/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8644/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8645/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8646/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8647/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8648/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8649/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8650/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8651/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8652/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8653/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8654/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8655/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8656/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8657/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8658/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8659/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08659: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8660/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8661/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8662/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8663/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8664/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8665/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8666/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8667/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8668/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8669/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8670/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8671/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8672/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8673/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8674/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8675/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8676/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8677/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8678/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8679/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08679: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8680/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8681/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8682/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8683/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8684/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8685/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8686/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8687/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8688/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8689/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8690/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8691/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8692/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8693/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8694/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8695/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8696/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8697/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8698/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8699/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08699: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8700/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8701/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8702/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8703/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8704/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8705/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8706/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8707/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8708/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8709/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8710/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8711/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8712/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8713/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8714/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8715/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8716/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8717/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8718/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8719/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08719: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8720/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8721/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8722/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8723/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8724/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8725/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8726/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8727/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8728/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8729/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8730/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8731/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8732/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8733/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8734/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8735/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8736/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8737/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8738/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8739/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08739: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8740/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8741/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8742/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8743/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8744/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8745/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8746/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8747/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8748/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8749/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8750/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8751/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8752/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8753/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8754/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8755/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8756/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8757/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8758/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8759/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08759: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8760/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8761/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8762/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8763/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8764/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8765/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8766/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8767/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8768/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8769/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8770/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8771/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8772/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8773/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8774/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8775/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8776/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8777/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8778/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8779/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08779: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8780/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8781/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8782/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8783/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8784/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8785/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8786/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8787/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8788/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8789/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8790/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8791/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8792/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8793/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8794/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8795/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8796/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8797/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8798/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8799/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08799: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8800/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8801/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8802/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8803/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8804/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8805/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8806/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8807/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8808/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8809/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8810/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8811/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8812/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8813/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8814/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8815/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8816/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8817/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8818/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8819/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08819: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8820/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8821/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8822/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8823/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8824/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8825/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8826/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8827/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8828/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8829/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8830/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8831/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8832/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8833/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8834/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8835/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8836/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8837/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8838/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8839/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08839: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8840/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8841/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8842/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8843/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8844/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8845/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8846/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8847/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8848/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8849/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8850/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8851/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8852/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8853/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8854/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8855/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8856/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8857/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8858/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8859/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08859: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8860/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8861/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8862/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8863/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8864/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8865/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8866/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8867/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8868/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8869/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8870/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8871/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8872/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8873/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8874/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8875/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8876/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8877/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8878/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8879/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08879: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8880/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8881/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8882/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8883/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8884/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8885/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8886/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8887/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8888/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8889/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8890/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8891/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8892/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8893/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8894/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8895/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8896/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8897/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8898/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8899/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08899: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8900/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8901/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8902/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8903/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8904/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8905/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8906/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8907/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8908/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8909/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8910/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8911/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8912/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8913/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8914/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8915/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8916/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8917/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8918/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8919/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08919: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8920/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8921/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8922/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8923/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8924/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8925/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8926/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8927/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8928/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8929/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8930/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8931/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8932/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8933/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8934/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8935/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8936/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8937/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8938/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8939/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08939: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8940/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8941/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8942/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8943/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8944/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8945/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8946/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8947/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8948/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8949/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8950/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8951/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8952/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8953/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8954/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8955/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8956/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8957/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8958/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8959/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08959: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8960/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8961/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8962/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8963/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8964/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8965/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8966/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8967/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8968/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8969/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8970/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8971/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8972/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8973/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8974/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8975/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8976/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8977/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8978/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8979/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08979: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 8980/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8981/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8982/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8983/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8984/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8985/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8986/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8987/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8988/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8989/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8990/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8991/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8992/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8993/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8994/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8995/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8996/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8997/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8998/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 8999/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 08999: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9000/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9001/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9002/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9003/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9004/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9005/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9006/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9007/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9008/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9009/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9010/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9011/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9012/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9013/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9014/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9015/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9016/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9017/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9018/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9019/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09019: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9020/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9021/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9022/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9023/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9024/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9025/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9026/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9027/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9028/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9029/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9030/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9031/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9032/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9033/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9034/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9035/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9036/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9037/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9038/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9039/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09039: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9040/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9041/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9042/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9043/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9044/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9045/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9046/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9047/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9048/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9049/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9050/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9051/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9052/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9053/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9054/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9055/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9056/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9057/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9058/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9059/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09059: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9060/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9061/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9062/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9063/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9064/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9065/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9066/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9067/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9068/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9069/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9070/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9071/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9072/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9073/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9074/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9075/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9076/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9077/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9078/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9079/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09079: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9080/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9081/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9082/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9083/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9084/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9085/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9086/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9087/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9088/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9089/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9090/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9091/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9092/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9093/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9094/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9095/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9096/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9097/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9098/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9099/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09099: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9100/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9101/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9102/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9103/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9104/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9105/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9106/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9107/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9108/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9109/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9110/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9111/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9112/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9113/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9114/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9115/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9116/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9117/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9118/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9119/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09119: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9120/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9121/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9122/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9123/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9124/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9125/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9126/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9127/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9128/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9129/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9130/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9131/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9132/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9133/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9134/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9135/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9136/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9137/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9138/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9139/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09139: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9140/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9141/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9142/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9143/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9144/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9145/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9146/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9147/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9148/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9149/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9150/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9151/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9152/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9153/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9154/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9155/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9156/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9157/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9158/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9159/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09159: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9160/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9161/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9162/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9163/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9164/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9165/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9166/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9167/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9168/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9169/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9170/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9171/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9172/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9173/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9174/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9175/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9176/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9177/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9178/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9179/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09179: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9180/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9181/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9182/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9183/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9184/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9185/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9186/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9187/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9188/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9189/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9190/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9191/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9192/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9193/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9194/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9195/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9196/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9197/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9198/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9199/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09199: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9200/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9201/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9202/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9203/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9204/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9205/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9206/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9207/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9208/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9209/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9210/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9211/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9212/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9213/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9214/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9215/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9216/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9217/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9218/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9219/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09219: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9220/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9221/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9222/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9223/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9224/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9225/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9226/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9227/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9228/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9229/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9230/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9231/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9232/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9233/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9234/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9235/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9236/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9237/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9238/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9239/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09239: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9240/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9241/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9242/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9243/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9244/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9245/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9246/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9247/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9248/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9249/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9250/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9251/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9252/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9253/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9254/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9255/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9256/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9257/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9258/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9259/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09259: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9260/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9261/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9262/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9263/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9264/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9265/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9266/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9267/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9268/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9269/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9270/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9271/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9272/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9273/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9274/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9275/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9276/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9277/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9278/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9279/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09279: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9280/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9281/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9282/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9283/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9284/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9285/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9286/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9287/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9288/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9289/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9290/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9291/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9292/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9293/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9294/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9295/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9296/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9297/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9298/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9299/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09299: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9300/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9301/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9302/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9303/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9304/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9305/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9306/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9307/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9308/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9309/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9310/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9311/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9312/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9313/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9314/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9315/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9316/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9317/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9318/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9319/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09319: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9320/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9321/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9322/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9323/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9324/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9325/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9326/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9327/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9328/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9329/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9330/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9331/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9332/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9333/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9334/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9335/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9336/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9337/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9338/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9339/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09339: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9340/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9341/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9342/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9343/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9344/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9345/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9346/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9347/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9348/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9349/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9350/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9351/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9352/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9353/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9354/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9355/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9356/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9357/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9358/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9359/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09359: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9360/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9361/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9362/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9363/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9364/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9365/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9366/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9367/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9368/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9369/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9370/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9371/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9372/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9373/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9374/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9375/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9376/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9377/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9378/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9379/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09379: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9380/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9381/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9382/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9383/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9384/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9385/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9386/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9387/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9388/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9389/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9390/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9391/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9392/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9393/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9394/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9395/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9396/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9397/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9398/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9399/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09399: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9400/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9401/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9402/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9403/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9404/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9405/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9406/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9407/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9408/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9409/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9410/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9411/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9412/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9413/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9414/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9415/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9416/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9417/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9418/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9419/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09419: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9420/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9421/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9422/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9423/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9424/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9425/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9426/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9427/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9428/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9429/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9430/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9431/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9432/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9433/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9434/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9435/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9436/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9437/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9438/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9439/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09439: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9440/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9441/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9442/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9443/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9444/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9445/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9446/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9447/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9448/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9449/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9450/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9451/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9452/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9453/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9454/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9455/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9456/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9457/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9458/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9459/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09459: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9460/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9461/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9462/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9463/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9464/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9465/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9466/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9467/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9468/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9469/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9470/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9471/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9472/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9473/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9474/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9475/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9476/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9477/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9478/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9479/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09479: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9480/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9481/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9482/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9483/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9484/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9485/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9486/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9487/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9488/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9489/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9490/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9491/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9492/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9493/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9494/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9495/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9496/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9497/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9498/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9499/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09499: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9500/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9501/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9502/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9503/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9504/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9505/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9506/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9507/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9508/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9509/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9510/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9511/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9512/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9513/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9514/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9515/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9516/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9517/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9518/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9519/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09519: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9520/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9521/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9522/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9523/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9524/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9525/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9526/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9527/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9528/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9529/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9530/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9531/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9532/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9533/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9534/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9535/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9536/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9537/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9538/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9539/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09539: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9540/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9541/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9542/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9543/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9544/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9545/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9546/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9547/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9548/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9549/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9550/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9551/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9552/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9553/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9554/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9555/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9556/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9557/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9558/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9559/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09559: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9560/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9561/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9562/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9563/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9564/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9565/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9566/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9567/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9568/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9569/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9570/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9571/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9572/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9573/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9574/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9575/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9576/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9577/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9578/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9579/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09579: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9580/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9581/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9582/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9583/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9584/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9585/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9586/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9587/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9588/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9589/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9590/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9591/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9592/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9593/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9594/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9595/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9596/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9597/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9598/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9599/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09599: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9600/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9601/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9602/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9603/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9604/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9605/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9606/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9607/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9608/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9609/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9610/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9611/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9612/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9613/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9614/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9615/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9616/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9617/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9618/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9619/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09619: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9620/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9621/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9622/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9623/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9624/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9625/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9626/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9627/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9628/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9629/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9630/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9631/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9632/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9633/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9634/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9635/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9636/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9637/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9638/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9639/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09639: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9640/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9641/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9642/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9643/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9644/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9645/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9646/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9647/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9648/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9649/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9650/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9651/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9652/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9653/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9654/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9655/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9656/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9657/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9658/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9659/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09659: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9660/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9661/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9662/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9663/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9664/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9665/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9666/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9667/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9668/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9669/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9670/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9671/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9672/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9673/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9674/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9675/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9676/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9677/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9678/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9679/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09679: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9680/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9681/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9682/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9683/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9684/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9685/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9686/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9687/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9688/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9689/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9690/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9691/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9692/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9693/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9694/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9695/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9696/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9697/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9698/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9699/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09699: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9700/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9701/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9702/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9703/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9704/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9705/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9706/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9707/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9708/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9709/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9710/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9711/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9712/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9713/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9714/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9715/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9716/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9717/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9718/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9719/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09719: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9720/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9721/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9722/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9723/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9724/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9725/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9726/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9727/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9728/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9729/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9730/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9731/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9732/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9733/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9734/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9735/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9736/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9737/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9738/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9739/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09739: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9740/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9741/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9742/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9743/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9744/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9745/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9746/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9747/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9748/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9749/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9750/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9751/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9752/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9753/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9754/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9755/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9756/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9757/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9758/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9759/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09759: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9760/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9761/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9762/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9763/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9764/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9765/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9766/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9767/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9768/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9769/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9770/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9771/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9772/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9773/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9774/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9775/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9776/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9777/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9778/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9779/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09779: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9780/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9781/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9782/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9783/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9784/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9785/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9786/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9787/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9788/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9789/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9790/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9791/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9792/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9793/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9794/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9795/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9796/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9797/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9798/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9799/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09799: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9800/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9801/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9802/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9803/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9804/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9805/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9806/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9807/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9808/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9809/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9810/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9811/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9812/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9813/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9814/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9815/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9816/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9817/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9818/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9819/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09819: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9820/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9821/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9822/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9823/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9824/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9825/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9826/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9827/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9828/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9829/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9830/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9831/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9832/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9833/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9834/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9835/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9836/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9837/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9838/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9839/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09839: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9840/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9841/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9842/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9843/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9844/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9845/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9846/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9847/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9848/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9849/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9850/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9851/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9852/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9853/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9854/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9855/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9856/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9857/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9858/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9859/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09859: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9860/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9861/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9862/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9863/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9864/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9865/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9866/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9867/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9868/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9869/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9870/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9871/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9872/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9873/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9874/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9875/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9876/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9877/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9878/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9879/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09879: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9880/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9881/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9882/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9883/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9884/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9885/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9886/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9887/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9888/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9889/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9890/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9891/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9892/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9893/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9894/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9895/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9896/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9897/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9898/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9899/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09899: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9900/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9901/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9902/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9903/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9904/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9905/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9906/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9907/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9908/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9909/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9910/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9911/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9912/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9913/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9914/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9915/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9916/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9917/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9918/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9919/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09919: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9920/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9921/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9922/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9923/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9924/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9925/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9926/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9927/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9928/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9929/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9930/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9931/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9932/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9933/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9934/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9935/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9936/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9937/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9938/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9939/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09939: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9940/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9941/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9942/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9943/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9944/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9945/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9946/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9947/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9948/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9949/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9950/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9951/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9952/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9953/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9954/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9955/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9956/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9957/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9958/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9959/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09959: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9960/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9961/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9962/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9963/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9964/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9965/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9966/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9967/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9968/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9969/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9970/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9971/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9972/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9973/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9974/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9975/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9976/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9977/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9978/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9979/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09979: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 9980/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9981/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9982/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9983/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9984/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9985/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9986/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9987/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9988/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9989/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9990/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9991/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9992/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9993/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9994/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9995/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9996/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9997/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9998/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "Epoch 9999/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 09999: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 10000/10000\n",
            " - 0s - loss: 0.1269 - accuracy: 0.8090 - val_loss: 0.1336 - val_accuracy: 0.8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "xVgHCvw8ZRh9",
        "outputId": "80c2873e-e221-48eb-9585-f169ec48fe4a"
      },
      "source": [
        "logs = history.history\n",
        "plt.plot(logs['accuracy'])\n",
        "plt.plot(logs['val_accuracy'])\n",
        "plt.title('acc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'acc')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "KAebLeLmZT9j",
        "outputId": "dd829d25-86d8-4e67-be36-8933b7c51f4b"
      },
      "source": [
        "plt.plot(logs['loss'])\n",
        "plt.plot(logs['val_loss'])\n",
        "plt.title('loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAMAX-G9nRal",
        "outputId": "df285d27-d426-4089-ee8b-236304bb4ed4"
      },
      "source": [
        "testdata = pd.read_csv('/content/drive/MyDrive/kaggel/test.csv')\n",
        "ansdata = testdata[row_name[0]]\n",
        "delet_col = [row_name[0],row_name[3],row_name[6],row_name[7],row_name[8],row_name[9],row_name[11]]\n",
        "testdata = testdata.drop(delet_col, axis=1)\n",
        "testdata = testdata.replace(['male', 'female'],[1, 0])\n",
        "testdata['Age'] = testdata['Age'].fillna(value=data_new['Age'].mean())\n",
        "strlist2 = list(testdata['Cabin'].unique())\n",
        "testdata['Cabin']=testdata['Cabin'].fillna(0)\n",
        "for element in strlist2:\n",
        "    testdata['Cabin']=testdata['Cabin'].replace(element,1)\n",
        "\n",
        "predictions = model.predict(testdata)\n",
        "print(predictions.round())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an9Fs9SbtTf3",
        "outputId": "70912479-919a-41ac-b9a4-46270c30de89"
      },
      "source": [
        "#print(predictions.type)\n",
        "\n",
        "predictions =predictions.round()\n",
        "predictions = pd.DataFrame(predictions,columns=['Survived'])\n",
        "predictions[row_name[0]] = ansdata\n",
        "predictions =predictions[['PassengerId','Survived']]\n",
        "print(predictions)\n",
        "\n",
        "\n",
        "predictions.to_csv('/content/drive/MyDrive/kaggel/ans.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     PassengerId  Survived\n",
            "0            892       0.0\n",
            "1            893       1.0\n",
            "2            894       0.0\n",
            "3            895       0.0\n",
            "4            896       0.0\n",
            "..           ...       ...\n",
            "413         1305       0.0\n",
            "414         1306       1.0\n",
            "415         1307       0.0\n",
            "416         1308       0.0\n",
            "417         1309       0.0\n",
            "\n",
            "[418 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}